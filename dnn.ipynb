{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dnn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maram-Elsayed/Flower-Recognizer-in-Python/blob/master/dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ-BeTifeeGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KyBwHQ6eo6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n4d68pbeqrj",
        "colab_type": "code",
        "outputId": "8a109ed4-8d0e-438f-93d4-93983703da9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "import cv2\n",
        "import keras\n",
        "from PIL import Image\n",
        "import os, os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from scipy import ndimage, misc\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19EfgHRLe2Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageDir_train = [\"drive/Colab/daisy_0/\",\"drive/Colab/dandelion_1/\",\"drive/Colab/rose_2/\",\"drive/Colab/sunflower_3/\",\"drive/Colab/tulip_4/\"]\n",
        "\n",
        "y=0\n",
        "train_x=[]\n",
        "flowers=np.array([['Pixels','Target']])\n",
        "#image_path_list=[]\n",
        "train_y=np.array([])\n",
        "valid_image_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
        "valid_image_extensions = [item.lower() for item in valid_image_extensions]\n",
        "for f in range(len(imageDir_train)): \n",
        " image_path_list_train=[]\n",
        " for file in os.listdir(imageDir_train[f]):    \n",
        "    extension = os.path.splitext(file)[1]\n",
        "    if extension.lower() not in valid_image_extensions:\n",
        "        continue\n",
        "    image_path_list_train.append(os.path.join(imageDir_train[f], file))\n",
        "    #train_y=np.append(train_y,[imageDir[f][-2:-1]])\n",
        "\n",
        "\n",
        "\n",
        " for imagePath in image_path_list_train:\n",
        "   i= np.array(Image.open(imagePath))\n",
        "   #gray = cv2.cvtColor(i,cv2.COLOR_BGR2GRAY)\n",
        "   res = cv2.resize(i, dsize=(320, 230), interpolation=cv2.INTER_CUBIC)\n",
        "   iar=np.asarray(res)\n",
        "   #train_x.append(iar)\n",
        "   flowers=np.append(flowers,[[iar,imageDir_train[f][-2:-1]]] ,0)\n",
        "   y+=1\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaLu5xIxe2Lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageDir_test = [\"drive/Colab/daisy_test_0/\",\"drive/Colab/dandelion_test_1/\",\"drive/Colab/rose_test_2/\",\"drive/Colab/sunflower_test_3/\",\"drive/Colab/tulip_test_4/\"]\n",
        "\n",
        "\n",
        "y=0\n",
        "test_x=[]\n",
        "test=np.array([['Pixels','Target']])\n",
        "test_y=np.array([])\n",
        "valid_image_extensions_test = [\".jpg\", \".jpeg\", \".png\"]\n",
        "valid_image_extensions_test = [item.lower() for item in valid_image_extensions_test]\n",
        "for f in range(len(imageDir_test)):\n",
        " image_path_list_test=[] \n",
        " for file in os.listdir(imageDir_test[f]):    \n",
        "    extension = os.path.splitext(file)[1]\n",
        "    if extension.lower() not in valid_image_extensions_test:\n",
        "        continue\n",
        "    image_path_list_test.append(os.path.join(imageDir_test[f], file))\n",
        "    #train_y=np.append(train_y,[imageDir[f][-2:-1]])\n",
        "\n",
        "\n",
        "\n",
        " for imagePath in image_path_list_test:\n",
        "   i= np.array(Image.open(imagePath))\n",
        "   #gray = cv2.cvtColor(i,cv2.COLOR_BGR2GRAY)\n",
        "   res = cv2.resize(i, dsize=(320, 230), interpolation=cv2.INTER_CUBIC)\n",
        "   iar=np.asarray(res)\n",
        "   test=np.append(test,[[iar,imageDir_test[f][-2:-1]]] ,0)\n",
        "   y+=1\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SNkjL64e2Rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flowers = np.delete(flowers, (0), axis=0)\n",
        "test = np.delete(test, (0), axis=0)\n",
        "np.random.shuffle(flowers)\n",
        "np.random.shuffle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2zzpbHyfIOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(len(flowers)):\n",
        " train_y=np.append(train_y,[flowers[x][1]])\n",
        "for x in range(len(flowers)):\n",
        " train_x.append(flowers[x][0])\n",
        "train_x=np.array(train_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flv1nIqzfIaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(len(test)):\n",
        " test_y=np.append(test_y,[test[x][1]])\n",
        "for x in range(len(test)):\n",
        " test_x.append(test[x][0])\n",
        "test_x=np.array(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haKegHNkfMm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = train_x.reshape(3010,220800)\n",
        "test_x = test_x.reshape(360,220800)\n",
        "train_x = train_x.astype('float32')\n",
        "test_x = test_x.astype('float32')\n",
        "train_x /= 255\n",
        "test_x /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5BNy075fMp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y= to_categorical(train_y)\n",
        "test_y= to_categorical(test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bza6cG-_fMvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_x=train_x[-501:]\n",
        "train_x=train_x[:-501]\n",
        "valid_y=train_y[-501:]\n",
        "train_y=train_y[:-501]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfhVIH_yfMtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(220800,)))\n",
        "model.add(Activation('relu'))                              \n",
        "model.add(Dropout(0.25))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(512, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(Dense(512, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.01))  \n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToCz6eU2IONp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRPFePfIQ-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "   keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=3,\n",
        "                              verbose=1, mode='auto')\n",
        "]\n",
        "fashion_train = model.fit(train_x, train_y, batch_size=40,epochs=30,verbose=1,validation_data=(valid_x, valid_y),callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RBdCUtVbFFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_eval = model.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}